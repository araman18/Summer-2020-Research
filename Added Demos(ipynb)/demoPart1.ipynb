{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "demoPart1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljystTA_KzDy",
        "colab_type": "text"
      },
      "source": [
        "https://docs.google.com/document/d/1jo1R88kBe7U1PmCbhRvcneADTL0yc3EAcQABYuUEhfc/edit# Markup\n",
        "De Novo Drug Design https://advances.sciencemag.org/content/4/7/eaap7885\n",
        "# Reinforcement Learning For Structural Evolution.\n",
        "This experiement ReLeaSe has two significant parts.\n",
        "## PART 1 - Use a StackRNN to transform chemical formulas for compounds into a SMILE representation, \n",
        "* SMILE is just a String ecnoding for this chemical formula that makes it easier to perform the second part of the experiment.<br>  <br>\n",
        "* A StackRNN which is a variant of an RNN is used to convert any new chemical formula into the SMILE version.<br>\n",
        "* An example can be seen in the 2 strings below converted from Carbon monoxide and carbon.<br>\n",
        "<br>\n",
        "<b>CO->CHEMBL14688</b><br>\n",
        "<b>C->CHEMBL17564</b><br>\n",
        "<br>\n",
        "* This conversion is especially useful when regarding formulas with double and triple bonds,like below.<br>\n",
        "<br>\n",
        "<b>CC(O)=O->CHEMBL539</b><br>\n",
        "<b>CC(N)=S</b><br>\n",
        "<br>\n",
        "* This property is especially useful in this use case since most of the formulas that will be modified are goingto be complex and thus a system like SMILE is used effectively.<br>\n",
        "## PART 2- Training a generative and predictive model together and use reinforcement learning to bias towards desired properties in the generated compounds.\n",
        "* In this part of the experiment the valid SMILE strings are fed into a LSTM (Long short term memory network).\n",
        "* There will be more elaboration about this in the future since there is a lot to say.\n",
        "* The graphic below is a good description of the experiment flow taken from https://github.com/isayev/ReLeaSE\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Der6EmUZJGMu",
        "colab_type": "code",
        "outputId": "d0def70a-cf1b-41f4-fa05-d9eb065c6057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!git clone https://github.com/isayev/ReLeaSE.git\n",
        "%cd ReLeaSE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ReLeaSE' already exists and is not an empty directory.\n",
            "/content/ReLeaSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKlsHDQ1Jrgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3f1364b-d71f-4866-f30a-33acf0ecf936"
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda create -c rdkit -n my-rdkit-env rdkit python=3.6\n",
        "!source activate my-rdkit-env\n",
        "!conda install --yes --file conda_requirements.txt\n",
        "!conda install -c rdkit rdkit nox cairo\n",
        "!conda install pytorch\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "!pip install  -r pip_requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-02 23:02:50--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "unlinking: ca-certificates-2020.1.1-0\n",
            "unlinking: certifi-2020.4.5.1-py36_0\n",
            "unlinking: conda-4.8.3-py36_0\n",
            "unlinking: cryptography-2.9.2-py36h1ba5d50_0\n",
            "unlinking: libgcc-ng-9.1.0-hdf63c60_0\n",
            "unlinking: libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "unlinking: openssl-1.1.1g-h7b6447c_0\n",
            "unlinking: python-3.6.8-h0371630_0\n",
            "unlinking: setuptools-46.4.0-py36_0\n",
            "unlinking: sqlite-3.26.0-h7b6447c_0\n",
            "unlinking: tk-8.6.8-hbc83047_0\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/my-rdkit-env\n",
            "\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - ipykernel\n",
            "    - ipython\n",
            "    - numpy\n",
            "    - pytest\n",
            "    - pytest-cov\n",
            "    - scikit-learn==0.20.2\n",
            "    - scipy\n",
            "    - seaborn==0.9.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-8.0            |                3       322.4 MB\n",
            "    cudnn-7.1.3                |        cuda8.0_0       229.6 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       552.0 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates: 2018.03.07-0         --> 2020.1.1-0          \n",
            "    certifi:         2018.4.16-py36_0     --> 2020.4.5.1-py36_0   \n",
            "    conda:           4.5.4-py36_0         --> 4.8.3-py36_0        \n",
            "    cryptography:    2.2.2-py36h14c3975_0 --> 2.9.2-py36h1ba5d50_0\n",
            "    libgcc-ng:       7.2.0-hdf63c60_3     --> 9.1.0-hdf63c60_0    \n",
            "    libstdcxx-ng:    7.2.0-hdf63c60_3     --> 9.1.0-hdf63c60_0    \n",
            "    openssl:         1.0.2o-h20670df_0    --> 1.1.1g-h7b6447c_0   \n",
            "    python:          3.6.5-hc3d631a_2     --> 3.6.8-h0371630_0    \n",
            "    setuptools:      39.2.0-py36_0        --> 46.4.0-py36_0       \n",
            "    sqlite:          3.23.1-he433501_0    --> 3.26.0-h7b6447c_0   \n",
            "    tk:              8.6.7-hc745277_3     --> 8.6.8-hbc83047_0    \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "    cudatoolkit:     10.1.243-h6bb024c_0  --> 8.0-3               \n",
            "    cudnn:           7.6.5-cuda10.1_0     --> 7.1.3-cuda8.0_0     \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-8.0      | 322.4 MB | : 100% 1.0/1 [00:36<00:00, 36.49s/it]                \n",
            "cudnn-7.1.3          | 229.6 MB | : 100% 1.0/1 [00:27<00:00, 27.64s/it]                \n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::pytorch==1.4.0=cuda101py36h02f0884_0\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cairo\n",
            "    - nox\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  cudatoolkit                  pkgs/free::cudatoolkit-8.0-3 --> pkgs/main::cudatoolkit-10.1.243-h6bb024c_0\n",
            "  cudnn                                     7.1.3-cuda8.0_0 --> 7.6.5-cuda10.1_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Collecting mordred==1.1.2 (from -r pip_requirements.txt (line 1))\n",
            "  Using cached https://files.pythonhosted.org/packages/80/8d/70f26c38ba4bd3bda46791bef71b67bcb7442d6671f66459ad8feaa8eb22/mordred-1.1.2.tar.gz\n",
            "Collecting tensorboard==1.10.0 (from -r pip_requirements.txt (line 2))\n",
            "  Using cached https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl\n",
            "Collecting tqdm==4.26.0 (from -r pip_requirements.txt (line 3))\n",
            "  Using cached https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl\n",
            "Collecting xgboost==0.81 (from -r pip_requirements.txt (line 4))\n",
            "  Using cached https://files.pythonhosted.org/packages/54/21/8b2ec99862903a6d3aed62ce156d21d114b8666e669c46d9e54041df9496/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
            "Collecting tensorflow==1.13.0 (from -r pip_requirements.txt (line 5))\n",
            "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==1.13.0 (from -r pip_requirements.txt (line 5)) (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)\u001b[0m\n",
            "\u001b[31mNo matching distribution found for tensorflow==1.13.0 (from -r pip_requirements.txt (line 5))\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 142, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 109, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/__init__.py\", line 2, in <module>\n",
            "    from .connect import *\n",
            "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/connect.py\", line 13, in <module>\n",
            "    from IPython.core.profiledir import ProfileDir\n",
            "  File \"/usr/local/lib/python3.6/site-packages/IPython/__init__.py\", line 55, in <module>\n",
            "    from .core.application import Application\n",
            "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/application.py\", line 23, in <module>\n",
            "    from traitlets.config.application import Application, catch_config_error\n",
            "  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/__init__.py\", line 6, in <module>\n",
            "    from .application import *\n",
            "  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 17, in <module>\n",
            "    from decorator import decorator\n",
            "ModuleNotFoundError: No module named 'decorator'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2XVu7oNQLww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "ac053ecf-aa5b-4197-dcb2-7860ccb496e6"
      },
      "source": [
        "!python -m ipykernel install --user --name release --display-name ReLeaSE\n",
        "import sys\n",
        "sys.path.append('./release/')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 142, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"/usr/local/lib/python3.6/runpy.py\", line 109, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/__init__.py\", line 2, in <module>\n",
            "    from .connect import *\n",
            "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/connect.py\", line 13, in <module>\n",
            "    from IPython.core.profiledir import ProfileDir\n",
            "  File \"/usr/local/lib/python3.6/site-packages/IPython/__init__.py\", line 55, in <module>\n",
            "    from .core.application import Application\n",
            "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/application.py\", line 23, in <module>\n",
            "    from traitlets.config.application import Application, catch_config_error\n",
            "  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/__init__.py\", line 6, in <module>\n",
            "    from .application import *\n",
            "  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 17, in <module>\n",
            "    from decorator import decorator\n",
            "ModuleNotFoundError: No module named 'decorator'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idkg07nJQjSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y3Vn4AQQmH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPuBhIqxQqAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e6e3ab2b-9d85-46f5-89ee-2e3954f25c94"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import pickle\n",
        "from rdkit import Chem, DataStructs\n",
        "from release.stackRNN import StackAugmentedRNN\n",
        "from release.data import GeneratorData\n",
        "from release.utils import canonical_smiles\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKtoP4giKzD-",
        "colab_type": "text"
      },
      "source": [
        "# Explaining RNN's and the StackRNN used in this case\n",
        "* An RNN is a type of neural network more akin to understanding and predicting sequential information such as stock market quotes.\n",
        "* This is different from convolutional Neural networks which understand spatial input better.\n",
        "* In this case the RNN is tasked with taking in past mappings of chemical formulas to SMILE representations and outputting SMILEs for any future inputs.\n",
        "* Processing text data as input is a popular use for RNN which is what will be done in this case, break the input into sequences of characters\n",
        "* Leverages the concept of sequential memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dwcUU08QxJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_data_path = './data/testingdata.smi'\n",
        "tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
        "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
        "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', '\\n']\n",
        "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter='\\t', \n",
        "                         cols_to_read=[0], keep_header=True, tokens=tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYQmiBSSxeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_hist(prediction, n_to_generate):\n",
        "    print(\"Mean value of predictions:\", prediction.mean())\n",
        "    print(\"Proportion of valid SMILES:\", len(prediction)/n_to_generate)\n",
        "    ax = sns.kdeplot(prediction, shade=True)\n",
        "    ax.set(xlabel='Predicted pIC50', \n",
        "           title='Distribution of predicted pIC50 for generated molecules')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX4dByQ4S0Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estimate_and_update(generator, predictor, n_to_generate, **kwargs):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "\n",
        "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
        "    unique_smiles = list(np.unique(sanitized))[1:]\n",
        "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, get_features=get_fp)  \n",
        "                                                       \n",
        "    plot_hist(prediction, n_to_generate)\n",
        "        \n",
        "    return smiles, prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYEZGgtCS26q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "83202914-aadb-4c25-aedf-17dc780b8086"
      },
      "source": [
        "hidden_size = 1500\n",
        "stack_width = 1500\n",
        "stack_depth = 200\n",
        "layer_type = 'GRU'\n",
        "lr = 0.001\n",
        "optimizer_instance = torch.optim.Adadelta\n",
        "\n",
        "my_generator = StackAugmentedRNN(input_size=gen_data.n_characters, hidden_size=hidden_size,\n",
        "                                 output_size=gen_data.n_characters, layer_type=layer_type,\n",
        "                                 n_layers=1, is_bidirectional=False, has_stack=True,\n",
        "                                 stack_width=stack_width, stack_depth=stack_depth, \n",
        "                                 use_cuda=use_cuda, \n",
        "                                 optimizer_instance=optimizer_instance, lr=lr)\n",
        "print(my_generator)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StackAugmentedRNN(\n",
            "  (stack_controls_layer): Linear(in_features=1500, out_features=3, bias=True)\n",
            "  (stack_input_layer): Linear(in_features=1500, out_features=1500, bias=True)\n",
            "  (encoder): Embedding(45, 1500)\n",
            "  (rnn): GRU(3000, 1500)\n",
            "  (decoder): Linear(in_features=1500, out_features=45, bias=True)\n",
            "  (log_softmax): LogSoftmax()\n",
            "  (criterion): CrossEntropyLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVGgmcpsTBNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = './checkpoints/generator/checkpoint_biggest_rnn'\n",
        "my_generator.load_model(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yBz5bfvTHTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASIAotaDKzD_",
        "colab_type": "text"
      },
      "source": [
        "## How a typical RNN works\n",
        "* Image of a RNN below \n",
        "![image.png](attachment:image.png)\n",
        "* This unrolled network shows how an RNN uses previous information to guess values in the future.\n",
        "* Activation value from previous timesteps is passed on to the next to help in the prediction, the only timestep that doesn't use previous info is timestep 1.\n",
        "* A(n) or the activation passed on from the nth layer is calculated A(n) = g(w<sub>aa</sub>a<sup>(n-1)</sup> + w<sub>ax</sub>x<sup>(n-1)</sup> + b<sub>a</sub>)\n",
        "* In this equation w<sub>aa</sub> represents parameters passed between layers w<sub>ax</sub> represents parameters of the input, b<sub>a</sub> represents a bias and g is the actiavtion function. tanh.Relu\n",
        "* <hat>yhat</hat><sup>n</sup> or the nework output for a specific layer is computed as $\\hat{y}$<sup>n</sup> = g(w<sub>ya</sub>a<sup>(n)</sup>  + b<sub>y</sub>). However this function uses a different activation function as the one which computes the actiavtion passed between layers - Sigmoid.\n",
        "* It can be seen from these equations that RNN's use a dynamic programming approach to try to deal with sequential data calcualting y(N) from  y(n-1) y(n-2) etc, but the values that are closer in sequence to n tend to have more weight because of the vanishing gradient problem.\n",
        "* Each time step is a layer.\n",
        "* One problem here lies in the backpropogation method where in an RNN the earlier layers essentially learn less since the weights are changed less and less as the layers go further back in time.Vanishing gradient problem1\n",
        "* RNN suffer from short term memory, mitigated by use of LSTM's and GRU's but they can learn long term dependancies using gates, knowing what to add to the hidden state both long term and short term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMFGOD4wKzD_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## How the StackRNN works\n",
        "* This experiement uses a Stack Augmented RNN in place of a normal RNN in order to convert formulas into smile strings.\n",
        "* The goal is to be able to determine the pattern in forming sequences of letters that correspond to valid SMILE strings.\n",
        "### What is different between a StackRNN and regular RNN's like GRU and LSTM.\n",
        "* Normal RNN's like GRU's and LSTM's suffer from an inability to count, the most basic example of this is the Dyck language where a Dyck word must have balanced parentheses, but such words would not be able to be generated by a GRU or LSTM since they lack the memory to count parentheses and determine if it is balanced.\n",
        "* Similarly SMILE strings must have properly matched parentheses with multiple types of brackers, so the RNN that is used for SMILES must have memory.\n",
        "* Additionally, the rings of molecules muyst have correct valence for all atoms so we need stack memory to count that.\n",
        "* Another issue of normal RNN's but not GRU's is the short term memory issue that is why in this experiment we use the GRU with a Stack which solves the problem of short term memory and counting.\n",
        "* GRU's solve the short term memory problem by using gates, that regulate information flow, instead of just passing on the last few bits of information from the last few layers, the gates can learn what sequences of information are important whether they be from recently or a long time ago in the timestamps.\n",
        "* The way this experiment integrates GRU's and a Stack is shown below.\n",
        "![image.png](attachment:image.png)* \n",
        "* The Stack RNN has a new neuron or cell strucutre on top of the GRU cell, and has 2 additional multiplicative gates which act as a memory stack, and this allows it to learn dependancies in the long term.\n",
        "* The StackRNN also uses the SoftMax function as loss. This loss function provides a set of probabilities that adds up to one.\n",
        "* This function is able to map the probability ditribution to the ouput varieties or in this case which values/weights to adjust. \n",
        "* This is a good way of reducing the negative impact of the vanishing gradient problem since with this probabilistic approach to weights and value adjustment the lower levels or layers with smaller timestamps will not be neglected in modification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilDTE1arKzEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "cc81b215-05e9-4952-efc0-5e116fe9224f"
      },
      "source": [
        "!git clone --single-branch --branch develop https://github.com/Mariewelt/OpenChem.git"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenChem'...\n",
            "remote: Enumerating objects: 1561, done.\u001b[K\n",
            "remote: Total 1561 (delta 0), reused 0 (delta 0), pack-reused 1561\u001b[K\n",
            "Receiving objects: 100% (1561/1561), 108.66 MiB | 31.28 MiB/s, done.\n",
            "Resolving deltas: 100% (789/789), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZD_B8cKzEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e01c7abb-11a6-4dee-b6a8-2a96f864ab5a"
      },
      "source": [
        "!pip install -r pip_requirements.txt\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "from release.data import PredictorData\n",
        "from release.utils import get_desc, get_fp\n",
        "from mordred import Calculator, descriptors\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mordred==1.1.2 (from -r pip_requirements.txt (line 1))\n",
            "  Using cached https://files.pythonhosted.org/packages/80/8d/70f26c38ba4bd3bda46791bef71b67bcb7442d6671f66459ad8feaa8eb22/mordred-1.1.2.tar.gz\n",
            "Collecting tensorboard==1.10.0 (from -r pip_requirements.txt (line 2))\n",
            "  Using cached https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl\n",
            "Collecting tqdm==4.26.0 (from -r pip_requirements.txt (line 3))\n",
            "  Using cached https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl\n",
            "Collecting xgboost==0.81 (from -r pip_requirements.txt (line 4))\n",
            "  Using cached https://files.pythonhosted.org/packages/54/21/8b2ec99862903a6d3aed62ce156d21d114b8666e669c46d9e54041df9496/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
            "Collecting tensorflow==1.13.0 (from -r pip_requirements.txt (line 5))\n",
            "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==1.13.0 (from -r pip_requirements.txt (line 5)) (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)\u001b[0m\n",
            "\u001b[31mNo matching distribution found for tensorflow==1.13.0 (from -r pip_requirements.txt (line 5))\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2a11780f7cb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrelease\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictorData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrelease\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_fp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmordred\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCalculator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mordred'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}