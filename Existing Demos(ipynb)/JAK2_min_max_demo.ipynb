{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAK2 activity optimization with ReLeaSE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-85748b042ead>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-85748b042ead>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    In this experiment we will optimized parameters of pretrained generative RNN to produce molecules with maximized and minimized pIC50 for JAK2. We use policy gradient algorithm with custom reward function to bias the properties of generated molecules aka Reinforcement Learninf for Structural Evolution (ReLeaSE) as was proposed in **Popova, M., Isayev, O., & Tropsha, A. (2018). *Deep reinforcement learning for de novo drug design*. Science advances, 4(7), eaap7885.**\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "In this experiment we will optimized parameters of pretrained generative RNN to produce molecules with maximized and minimized pIC50 for JAK2. We use policy gradient algorithm with custom reward function to bias the properties of generated molecules aka Reinforcement Learninf for Structural Evolution (ReLeaSE) as was proposed in **Popova, M., Isayev, O., & Tropsha, A. (2018). *Deep reinforcement learning for de novo drug design*. Science advances, 4(7), eaap7885.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./release/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from rdkit import Chem, DataStructs\n",
    "from stackRNN import StackAugmentedRNN\n",
    "from data import GeneratorData\n",
    "from utils import canonical_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_data_path = './data/chembl_22_clean_1576904_sorted_std_final.smi'\n",
    "gen_data_path = 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    " tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
    "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
    "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CCO' 'CHEMBL545']\n",
      " ['C' 'CHEMBL17564']\n",
      " ['CO' 'CHEMBL14688']\n",
      " ['NCCS' 'CHEMBL602']\n",
      " ['NCCN' 'CHEMBL816']\n",
      " ['CN' 'CHEMBL43280']\n",
      " ['C=O' 'CHEMBL1255']\n",
      " ['CCN' 'CHEMBL14449']\n",
      " ['CSC' 'CHEMBL15580']\n",
      " ['CBr' 'CHEMBL48339']\n",
      " ['CI' 'CHEMBL115849']\n",
      " ['CF' 'CHEMBL116838']\n",
      " ['CC' 'CHEMBL135626']\n",
      " ['CNC=O' 'CHEMBL9240']\n",
      " ['CCCN' 'CHEMBL14409']\n",
      " ['CCCO' 'CHEMBL14687']\n",
      " ['O=CC#C' 'CHEMBL722']\n",
      " ['C=CC=O' 'CHEMBL721']\n",
      " ['CC#N' 'CHEMBL45211']\n",
      " ['CCCl' 'CHEMBL46058']\n",
      " ['NC#N' 'CHEMBL56279']\n",
      " ['CC=O' 'CHEMBL76101']\n",
      " ['SC#N' 'CHEMBL84336']\n",
      " ['FCF' 'CHEMBL115186']\n",
      " ['C#C' 'CHEMBL116336']\n",
      " ['CCl' 'CHEMBL117545']\n",
      " ['C=C' 'CHEMBL117822']\n",
      " ['COC' 'CHEMBL119178']\n",
      " ['CNC' 'CHEMBL120433']\n",
      " ['CCNCC' 'CHEMBL1189']\n",
      " ['CCC' 'CHEMBL135416']\n",
      " ['N#N' 'CHEMBL142438']\n",
      " ['CNO' 'CHEMBL144761']\n",
      " ['CNN' 'CHEMBL160520']\n",
      " ['C#N' 'CHEMBL183419']\n",
      " ['CC(C)O' 'CHEMBL582']\n",
      " ['CNC=O' 'CHEMBL9081']\n",
      " ['CCCCON' 'CHEMBL6960']\n",
      " ['CCNC=O' 'CHEMBL9421']\n",
      " ['CC(O)=O' 'CHEMBL539']\n",
      " ['CCCCO' 'CHEMBL14245']\n",
      " ['CCCCN' 'CHEMBL13968']\n",
      " ['COCOC' 'CHEMBL15537']\n",
      " ['CCC#N' 'CHEMBL15871']\n",
      " ['CCCCC' 'CHEMBL16102']\n",
      " ['CCOCC' 'CHEMBL16264']\n",
      " ['NC(N)=N' 'CHEMBL821']\n",
      " ['ClCCl' 'CHEMBL45967']\n",
      " ['NCC=C' 'CHEMBL57286']\n",
      " ['NC(N)=O' 'CHEMBL985']\n",
      " ['NCCO' 'CHEMBL104943']\n",
      " ['OCCF' 'CHEMBL115586']\n",
      " ['CC=C' 'CHEMBL117213']\n",
      " ['OC=O' 'CHEMBL116736']\n",
      " ['CC#C' 'CHEMBL116902']\n",
      " ['CCCC' 'CHEMBL134702']\n",
      " ['CCBr' 'CHEMBL156378']\n",
      " ['CNNC' 'CHEMBL162921']\n",
      " ['CC=O' 'CHEMBL170365']\n",
      " ['OCCS' 'CHEMBL254951']\n",
      " ['NC=O' 'CHEMBL266160']\n",
      " ['ON=C' 'CHEMBL324784']\n",
      " ['OCCO' 'CHEMBL457299']\n",
      " ['CON' 'CHEMBL1213633']\n",
      " ['CCCCl' 'CHEMBL15697']\n",
      " ['CS(C)=O' 'CHEMBL504']\n",
      " ['ON=C' 'CHEMBL185198']\n",
      " ['Cn1ccnc1' 'CHEMBL543']\n",
      " ['CCCCCO' 'CHEMBL14568']\n",
      " ['CCCCCC' 'CHEMBL15939']\n",
      " ['ClCCCl' 'CHEMBL16370']\n",
      " ['CCCC#C' 'CHEMBL16262']\n",
      " ['OCC(O)CO' 'CHEMBL692']\n",
      " ['CN1CCCC1' 'CHEMBL665']\n",
      " ['CC(=O)NO' 'CHEMBL734']\n",
      " ['NCC(O)=O' 'CHEMBL773']\n",
      " ['CCCCCF' 'CHEMBL42434']\n",
      " ['CCOC=O' 'CHEMBL44215']\n",
      " ['CCCCCl' 'CHEMBL47259']\n",
      " ['NCCCCN' 'CHEMBL46257']\n",
      " ['NNC(N)=O' 'CHEMBL903']\n",
      " ['CCNCCN' 'CHEMBL70445']\n",
      " ['CNCCO' 'CHEMBL104083']\n",
      " ['N=C=N' 'CHEMBL116583']\n",
      " ['NCCCO' 'CHEMBL115530']\n",
      " ['C=C=C' 'CHEMBL116960']\n",
      " ['CCC=C' 'CHEMBL117210']\n",
      " ['CCSCC' 'CHEMBL117181']\n",
      " ['CC#CC' 'CHEMBL119108']\n",
      " ['NCCCN' 'CHEMBL174324']\n",
      " ['OCCCl' 'CHEMBL191244']\n",
      " ['OCC=C' 'CHEMBL234926']\n",
      " ['NC(=O)NO' 'CHEMBL467']\n",
      " ['CCC=O' 'CHEMBL275626']\n",
      " ['CSCCO' 'CHEMBL277871']\n",
      " ['COC=O' 'CHEMBL295026']\n",
      " ['ClCBr' 'CHEMBL346918']\n",
      " ['C1CCSC1' 'CHEMBL1379']\n",
      " ['COCCO' 'CHEMBL444144']\n",
      " ['OCCCO' 'CHEMBL379652']\n",
      " ['OCCBr' 'CHEMBL468583']\n",
      " ['C1CN1' 'CHEMBL540990']\n",
      " ['CCON' 'CHEMBL1213044']\n",
      " ['OC#N' 'CHEMBL1161700']\n",
      " ['NCCF' 'CHEMBL1162280']\n",
      " ['NCC=O' 'CHEMBL296723']\n",
      " ['CCNC' 'CHEMBL1232589']\n",
      " ['CCCS' 'CHEMBL1236818']\n",
      " ['CSSC' 'CHEMBL1347061']\n",
      " ['CCNN' 'CHEMBL1359929']\n",
      " ['SC#N' 'CHEMBL1161685']\n",
      " ['NCCCC(O)=O' 'CHEMBL96']\n",
      " ['c1cnoc1' 'CHEMBL13257']\n",
      " ['Nc1ccccc1' 'CHEMBL538']\n",
      " ['CCCCCCO' 'CHEMBL14085']\n",
      " ['CC(C)=O' 'CHEMBL14253']\n",
      " ['c1cscn1' 'CHEMBL15605']\n",
      " ['CC(N)=O' 'CHEMBL16081']\n",
      " ['CCCCC=O' 'CHEMBL18602']\n",
      " ['C1CCNC1' 'CHEMBL22830']\n",
      " ['CC(N)=S' 'CHEMBL38737']\n",
      " ['CCC(C)O' 'CHEMBL45462']\n",
      " ['CN(C)CCO' 'CHEMBL1135']\n",
      " ['CC(C)N' 'CHEMBL117080']\n",
      " ['CCOC=C' 'CHEMBL116745']\n",
      " ['CCOCCO' 'CHEMBL119596']\n",
      " ['ClCCBr' 'CHEMBL160255']\n",
      " ['CCCCBr' 'CHEMBL160949']\n",
      " ['COCC#C' 'CHEMBL162694']\n",
      " ['OCCCCO' 'CHEMBL171623']\n",
      " ['CNCCCN' 'CHEMBL174165']\n",
      " ['C1CNCCN1' 'CHEMBL1412']\n",
      " ['OCNC=O' 'CHEMBL268447']\n",
      " ['NCCCON' 'CHEMBL281021']\n",
      " ['CCCC=C' 'CHEMBL295337']\n",
      " ['ClCCNCCCl' 'CHEMBL913']\n",
      " ['CC(F)F' 'CHEMBL325493']\n",
      " ['CSCCCO' 'CHEMBL332887']\n",
      " ['CCNNCC' 'CHEMBL350303']\n",
      " ['CN=C=S' 'CHEMBL396000']\n",
      " ['CN(C)C' 'CHEMBL439723']\n",
      " ['C=CC#N' 'CHEMBL445612']\n",
      " ['BrCCBr' 'CHEMBL452370']\n",
      " ['OCC(S)CS' 'CHEMBL1597']\n",
      " ['ClCC=C' 'CHEMBL451126']\n",
      " ['OCCCBr' 'CHEMBL466545']\n",
      " ['C1CC1' 'CHEMBL1796999']\n",
      " ['ClCC=O' 'CHEMBL506976']\n",
      " ['C1CO1' 'CHEMBL1743219']\n",
      " ['C=CC=C' 'CHEMBL537970']\n",
      " ['NCCCF' 'CHEMBL1162286']\n",
      " ['NCC#N' 'CHEMBL1193997']\n",
      " ['NCCCl' 'CHEMBL1190279']\n",
      " ['BrCBr' 'CHEMBL1229889']\n",
      " ['CCCBr' 'CHEMBL1230095']\n",
      " ['O=C=O' 'CHEMBL1231871']\n",
      " ['S=C=S' 'CHEMBL1365180']\n",
      " ['OCC#C' 'CHEMBL1563026']\n",
      " ['NCCBr' 'CHEMBL1697693']\n",
      " ['ClC=C' 'CHEMBL2311071']\n",
      " ['SCC=C' 'CHEMBL3222024']\n",
      " ['NNCCO' 'CHEMBL3183346']\n",
      " ['C1CS1' 'CHEMBL3184935']\n",
      " ['COCCl' 'CHEMBL3185256']\n",
      " ['CCCCS' 'CHEMBL3188256']\n",
      " ['OCCCS' 'CHEMBL3234722']\n",
      " ['NCC#C' 'CHEMBL3263480']\n",
      " ['BrC#N' 'CHEMBL3561885']\n",
      " ['CC=CCO' 'CHEMBL116709']\n",
      " ['CC=CCO' 'CHEMBL118459']\n",
      " ['CC(N)CS' 'CHEMBL37279']\n",
      " ['N#CN1CCC1' 'CHEMBL8123']\n",
      " ['Cc1ccccc1' 'CHEMBL9113']\n",
      " ['NCc1ccccc1' 'CHEMBL522']\n",
      " ['c1c[nH]cn1' 'CHEMBL540']\n",
      " ['COC(C)=O' 'CHEMBL14079']\n",
      " ['CCC(N)CC' 'CHEMBL14178']\n",
      " ['CCC(O)=O' 'CHEMBL14021']\n",
      " ['c1cncnc1' 'CHEMBL15562']\n",
      " ['c1ncncn1' 'CHEMBL15698']\n",
      " ['c1cnccn1' 'CHEMBL15797']\n",
      " ['CCC(C)=O' 'CHEMBL15849']\n",
      " ['C1CCCCC1' 'CHEMBL15980']\n",
      " ['C1CCNCC1' 'CHEMBL15487']\n",
      " ['c1ccnnc1' 'CHEMBL15719']\n",
      " ['NCCNCCNCCN' 'CHEMBL609']\n",
      " ['OCc1ccccc1' 'CHEMBL720']\n",
      " ['CCCC(C)C' 'CHEMBL30909']\n",
      " ['CC1CCCC1' 'CHEMBL30940']\n",
      " ['C=CCCC=C' 'CHEMBL31747']\n",
      " ['CC(C)CCN' 'CHEMBL42003']\n",
      " ['CC(Cl)Cl' 'CHEMBL45079']\n",
      " ['CCCCNC=O' 'CHEMBL45466']\n",
      " ['CCCC(C)O' 'CHEMBL45065']\n",
      " ['CCC(O)CC' 'CHEMBL47100']\n",
      " ['CCNCCNCC' 'CHEMBL54723']\n",
      " ['NCCSSCCN' 'CHEMBL61350']\n",
      " ['CNCCCCNC' 'CHEMBL61621']\n",
      " ['CN1CCNCC1' 'CHEMBL1011']\n",
      " ['NCC(N)=O' 'CHEMBL86954']\n",
      " ['FC(F)Cl' 'CHEMBL116155']\n",
      " ['FC(F)=C' 'CHEMBL116020']\n",
      " ['CC(N)CO' 'CHEMBL116663']\n",
      " ['CSCCCCO' 'CHEMBL117865']\n",
      " ['OCCNCCO' 'CHEMBL119604']]\n"
     ]
    }
   ],
   "source": [
    "#Generated data from created data generator, currently produces a memory error,\n",
    "#Got around this by adding some of the data to a csv file and using that instead, better solution is a way to convert the smi to csv\n",
    "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter='\\t', \n",
    "                         cols_to_read=[1], keep_header=True, tokens=tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot_hist** function plots histogram of predicted properties and a vertical line for thershold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(prediction, n_to_generate):\n",
    "    print(\"Mean value of predictions:\", prediction.mean())\n",
    "    print(\"Proportion of valid SMILES:\", len(prediction)/n_to_generate)\n",
    "    ax = sns.kdeplot(prediction, shade=True)\n",
    "    ax.set(xlabel='Predicted pIC50', \n",
    "           title='Distribution of predicted pIC50 for generated molecules')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**estimate_and_update** function:\n",
    "\n",
    "1) generates n_to_generate number of SMILES strings\n",
    "\n",
    "2) filters invalid SMILES\n",
    "\n",
    "3) predicts pIC50 for valid SMILES\n",
    "\n",
    "4) plots histogram of predicted pIC50\n",
    "\n",
    "5) Returns valid SMILES and their predicted pIC50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_and_update(generator, predictor, n_to_generate, **kwargs):\n",
    "    generated = []\n",
    "    pbar = tqdm(range(n_to_generate))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(\"Generating molecules...\")\n",
    "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
    "\n",
    "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
    "    unique_smiles = list(np.unique(sanitized))[1:]\n",
    "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, get_features=get_fp)  \n",
    "                                                       \n",
    "    plot_hist(prediction, n_to_generate)\n",
    "        \n",
    "    return smiles, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and training the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used stack augmented generative GRU as a generator. The model was trained to predict the next symbol from SMILES alphabet using the already generated prefix. Model was trained to minimize the cross-entropy loss between predicted symbol and ground truth symbol. Scheme of the generator when inferring new SMILES is shown below:\n",
    "\n",
    "<img src=\"./figures/generator.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize stack-augmented generative RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1500\n",
    "stack_width = 1500\n",
    "stack_depth = 200\n",
    "layer_type = 'GRU'\n",
    "lr = 0.001\n",
    "optimizer_instance = torch.optim.Adadelta\n",
    "\n",
    "my_generator = StackAugmentedRNN(input_size=gen_data.n_characters, hidden_size=hidden_size,\n",
    "                                 output_size=gen_data.n_characters, layer_type=layer_type,\n",
    "                                 n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                 stack_width=stack_width, stack_depth=stack_depth, \n",
    "                                 use_cuda=use_cuda, \n",
    "                                 optimizer_instance=optimizer_instance, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want train the model from scratch, uncomment the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './checkpoints/generator/checkpoint_biggest_rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#losses = my_generator.fit(gen_data, 1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_generator.evaluate(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_generator.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can skip the process of training and load the pretrained parameters into the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change in stackRNN.py to make it run on a CPU linux VM, can change back by deleting the \"map_location='cpu' in file\"\n",
    "my_generator.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we will use Random Forest predictor instead of Recurrent Neural Network, since the availability of the dataset with JAK2 activity data used in the \"Deep Reinforcement Learning for de novo Drug Design\" paper is restricted under the license agreement. Here instead we use the JAK2 activity data downladed from ChEMBL. The size of this dataset is ~2000 data points, which is not enough to build a reliable deep neural network. Is you want to see a demo with RNN, please checkout logP optimization demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import PredictorData\n",
    "from utils import get_desc, get_fp\n",
    "from mordred import Calculator, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import VanillaQSAR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = RFR\n",
    "model_params = {'n_estimators': 50, 'n_jobs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictor = VanillaQSAR(model_instance=model_instance,\n",
    "                           model_params=model_params,\n",
    "                           model_type='regressor',\n",
    "                          ensemble_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SMILES' 'pIC50']\n",
      " ['O=S(=O)(Nc1cccc(-c2cnc3ccccc3n2)c1)c1cccs1' '4.26']\n",
      " ['O=c1cc(-c2nc(-c3ccc(-c4cn(CCP(=O)(O)O)nn4)cc3)[nH]c2-c2ccc(F)cc2)cc[nH]1'\n",
      "  '4.34']\n",
      " ...\n",
      " ['CC1CN(S(=O)(=O)CC2CCC(N(C)c3[nH]cnc4nccc3-4)CC2)CC1CO' '10.78']\n",
      " ['CS(=O)(=O)N1CCC(Nc2ncccc2-c2cnc3[nH]ccc3n2)C1' '10.97']\n",
      " ['COC(=O)N1CCCCC(Nc2ncccc2-c2cnc3[nH]ccc3n2)C1' '10.97']]\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-e742b1f9cbb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictorData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/jak2_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ReLeaSE/release/predictor.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, data, cv_split)\u001b[0m\n\u001b[1;32m     45\u001b[0m         cross_val_data, cross_val_labels = cross_validation_split(x=x, y=y,\n\u001b[1;32m     46\u001b[0m                                                                   \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                                                   n_folds=self.ensemble_size)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             train_x = np.concatenate(cross_val_data[:i] +\n",
      "\u001b[0;32m~/Desktop/ReLeaSE/release/utils.py\u001b[0m in \u001b[0;36mcross_validation_split\u001b[0;34m(x, y, n_folds, split, folds)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mcv_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'stratified'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mcv_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/release/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 (\"Cannot have number of splits n_splits={0} greater\"\n\u001b[1;32m    328\u001b[0m                  \" than the number of samples: n_samples={1}.\")\n\u001b[0;32m--> 329\u001b[0;31m                 .format(self.n_splits, n_samples))\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "pred_data = PredictorData(path='./data/jak2_data.csv', get_features=get_fp, has_label=True)\n",
    "print(pred_data.binary_y)\n",
    "my_predictor.fit_model(pred_data, cv_split='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce the unbiased distribution of the property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smiles_unbiased, prediction_unbiased = estimate_and_update(my_generator,\n",
    "                                                           my_predictor,\n",
    "                                                           n_to_generate=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biasing the distribution of the generator with reinforcement learning (policy gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the generator and the predictor into a single pipeline. The generator produces new SMILES string, which is then evaluated by the predictor. Based on the obtain prediction and our goal, we assign a numerical reward value and update the parameters of the generator using policy gradient algorithm.\n",
    "\n",
    "<img src=\"./figures/rl_pipeline.png\">\n",
    "\n",
    "Policy gradient loss is defined as:\n",
    "$$\n",
    "L(S|\\theta) = -\\dfrac{1}{n}\\sum_{i=1}^{|S|} \\sum_{j=1}^{length(s_i)} R_i\\cdot \\gamma^i \\cdot \\log p(s_i|s_0 \\dots s_{i-1}\\theta),\n",
    "$$\n",
    "\n",
    "where $R_i$ is the reward obtained at time step $i$ $\\gamma$ is the discount factor and $p(s_i|s_0 \\dots s_{i-1}, \\theta)$ is the probability of the next character given the prefix, which we obtain from the generator. \n",
    "\n",
    "In our case the reward is the same for every time step and is equal to the reward for the whole molecule. Discount factor $\\gamma$ is a number close to $1.0$ (it could be $1.0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing pIC50 for JAK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reinforcement import Reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy of the generator that will be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator_max = StackAugmentedRNN(input_size=gen_data.n_characters, \n",
    "                                     hidden_size=hidden_size,\n",
    "                                     output_size=gen_data.n_characters, \n",
    "                                     layer_type=layer_type,\n",
    "                                     n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                     stack_width=stack_width, stack_depth=stack_depth, \n",
    "                                     use_cuda=use_cuda, \n",
    "                                     optimizer_instance=optimizer_instance, lr=lr)\n",
    "\n",
    "my_generator_max.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some parameters for the experiment\n",
    "n_to_generate = 200\n",
    "n_policy_replay = 10\n",
    "n_policy = 15\n",
    "n_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_moving_average(previous_values, new_value, ma_window_size=10):\n",
    "    value_ma = np.sum(previous_values[-(ma_window_size-1):]) + new_value\n",
    "    value_ma = value_ma/(len(previous_values[-(ma_window_size-1):]) + 1)\n",
    "    return value_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_max(smiles, predictor, invalid_reward=0.0, get_features=get_fp):\n",
    "    mol, prop, nan_smiles = predictor.predict([smiles], get_features=get_features)\n",
    "    if len(nan_smiles) == 1:\n",
    "        return invalid_reward\n",
    "    return np.exp(prop[0]/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reward function we will use here is \n",
    "$$\n",
    "R(s) = \\exp(\\dfrac{predictor(s)}{3}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 12)\n",
    "y = np.exp(x/3)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('pIC50 value')\n",
    "plt.ylabel('Reward value')\n",
    "plt.title('Reward function for JAK2 activity maximization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_max = Reinforcement(my_generator_max, my_predictor, get_reward_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_max = []\n",
    "rl_losses_max = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    for j in trange(n_policy, desc='Policy gradient...'):\n",
    "        cur_reward, cur_loss = RL_max.policy_gradient(gen_data, get_features=get_fp)\n",
    "        rewards_max.append(simple_moving_average(rewards_max, cur_reward)) \n",
    "        rl_losses_max.append(simple_moving_average(rl_losses_max, cur_loss))\n",
    "    \n",
    "    plt.plot(rewards_max)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.show()\n",
    "    plt.plot(rl_losses_max)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "        \n",
    "    smiles_cur, prediction_cur = estimate_and_update(RL_max.generator, \n",
    "                                                     my_predictor, \n",
    "                                                     n_to_generate,\n",
    "                                                     get_features=get_fp)\n",
    "    print('Sample trajectories:')\n",
    "    for sm in smiles_cur[:5]:\n",
    "        print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smiles_biased_max, prediction_biased_max = estimate_and_update(RL_max.generator, \n",
    "                                                           my_predictor,\n",
    "                                                           n_to_generate=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(prediction_biased_max,label='Maximized', shade=True, color='red')\n",
    "sns.kdeplot(prediction_unbiased, label='Unbiased', shade=True, color='grey')\n",
    "plt.xlabel('pIC50 values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizing pIC50 for JAK2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will minimize the pIC50 fpr JAK2.\n",
    "\n",
    "The reward function we will use here is \n",
    "$$\n",
    "R(s) = \\exp(\\dfrac{-predictor(s)}{3} + 3) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_min(smiles, predictor, invalid_reward=0.0, get_features=get_fp):\n",
    "    mol, prop, nan_smiles = predictor.predict([smiles], get_features=get_features)\n",
    "    if len(nan_smiles) == 1:\n",
    "        return invalid_reward\n",
    "    return np.exp(-prop[0]/3 + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 12)\n",
    "y = np.exp(-x/3 + 3)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('pIC50 value')\n",
    "plt.ylabel('Reward value')\n",
    "plt.title('Reward function for JAK2 activity minimization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy of the generator that will be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator_min = StackAugmentedRNN(input_size=gen_data.n_characters, hidden_size=hidden_size,\n",
    "                                 output_size=gen_data.n_characters, layer_type=layer_type,\n",
    "                                 n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                 stack_width=stack_width, stack_depth=stack_depth, \n",
    "                                 use_cuda=use_cuda, \n",
    "                                 optimizer_instance=optimizer_instance, lr=lr)\n",
    "my_generator_min.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_min = Reinforcement(my_generator_min, my_predictor, get_reward_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_min = []\n",
    "rl_losses_min = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    for j in trange(n_policy, desc='Policy gradient...'):\n",
    "        cur_reward, cur_loss = RL_min.policy_gradient(gen_data, get_features=get_fp)\n",
    "        rewards_min.append(simple_moving_average(rewards_min, cur_reward)) \n",
    "        rl_losses_min.append(simple_moving_average(rl_losses_min, cur_loss))\n",
    "    \n",
    "    plt.plot(rewards_min)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.show()\n",
    "    plt.plot(rl_losses_min)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "        \n",
    "    smiles_cur, prediction_cur = estimate_and_update(RL_min.generator, \n",
    "                                                     my_predictor, \n",
    "                                                     n_to_generate)\n",
    "    print('Sample trajectories:')\n",
    "    for sm in smiles_cur[:5]:\n",
    "        print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_biased_min, prediction_biased_min = estimate_and_update(RL_min.generator, \n",
    "                                                           my_predictor,\n",
    "                                                           n_to_generate=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(prediction_biased_max, label='Maximized', shade=True, color='red')\n",
    "sns.kdeplot(prediction_biased_min, label='Minimized', shade=True, color='blue')\n",
    "sns.kdeplot(prediction_unbiased, label='Unbiased', shade=True, color='grey')\n",
    "plt.xlabel('pIC50 values')\n",
    "plt.title('Distributions of predicted pIC50 for unbiased,' + \n",
    "          ' maximized and minimized generator')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing random molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will draw some random compounds from the biased library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import DrawingOptions\n",
    "from rdkit.Chem import Draw\n",
    "DrawingOptions.atomLabelFontSize = 50\n",
    "DrawingOptions.dotsPerAngstrom = 100\n",
    "DrawingOptions.bondLineWidth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecules with maximized pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_mols_max = [Chem.MolFromSmiles(sm, sanitize=True) for sm in smiles_biased_max]\n",
    "sanitized_gen_mols_max = [generated_mols_max[i] \n",
    "                          for i in np.where(np.array(generated_mols_max) != None)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_draw = 20\n",
    "ind = np.random.randint(0, len(sanitized_gen_mols_max), n_to_draw)\n",
    "mols_to_draw_max = [sanitized_gen_mols_max[i] for i in ind]\n",
    "legends = ['pIC50 = ' + str(prediction_biased_max[i]) for i in ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw.MolsToGridImage(mols_to_draw_max, molsPerRow=5, \n",
    "                     subImgSize=(300,300), legends=legends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecules with minimized pIC50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generated_mols_min = [Chem.MolFromSmiles(sm, sanitize=True) for sm in smiles_biased_min]\n",
    "sanitized_gen_mols_min = [generated_mols_min[i] \n",
    "                          for i in np.where(np.array(generated_mols_min) != None)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_draw = 20\n",
    "ind = np.random.randint(0, len(sanitized_gen_mols_min), n_to_draw)\n",
    "mols_to_draw_min = [sanitized_gen_mols_min[i] for i in ind]\n",
    "legends = ['pIC50 = ' + str(prediction_biased_min[i]) for i in ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw.MolsToGridImage(mols_to_draw_min, molsPerRow=5, \n",
    "                     subImgSize=(300,300), legends=legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
